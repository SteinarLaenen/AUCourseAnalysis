# Reader that, upon being called reads all data and writes it to a file in json
# format (Runs in python2)
import sys
import facebook
import json
# import cPickle 

if __name__ == '__main__':
    token = sys.argv[1] # Token generated by AUCSA on developers.facebook
    graph = facebook.GraphAPI(access_token=token)
    # Get target_group
    target_group = graph.search(type="group",
                                q="The excellent and diverse people of AUC")
    
    group_id = target_group[u'data'][0][u'id']
    feed = graph.get_all_connections(id=group_id, connection_name='feed')
    post_list = []
    post_i = 0
    for post in feed:
        # Do not filter yet, purely for convenience purposes to save everything
        # in one go        
        post_i += 1
        try:
            post_list.append(post)
        except: # In case of unexpected error due to facebook graph issues
            print """An unexpected error occured, in order to continue mining where 
            we left off, see the most recent post added""", post_list[-1]
            break # Continue to writing part while printing the most recent post
        # for continuation purpose
        if post_i == 15: # Temporarily abort after 15 posts
            break
        if post_i%100 == 0:
            print post_i, 'posts have been added'
    with open('feed.txt', 'wb') as f:
        # for post in post_list:
        #     f.writ
        f.write(json.dumps(post_list))
        # pickler = cPickle.Pickler(f)
        # pickler.dump(post_list)

    print "Saved data to feed.txt (using cPickle module), use cPickle.Unpickler() to retrieve the data"
    # relevant_posts =
    
# def filter_relevant
# to get comments of post:
# comments = graph.get_all_connections(id=post_id, connection_name='commments')
# Comments keys: created_time: str, message: str, id: str, from: {name: str, id: str},

# To get people who liked the post:
# likes = graph.get_all_connections(id=comment_id, connnection_name='likes')
# likes: data: [{id:, name:},], paging: { irrelevant info }]
